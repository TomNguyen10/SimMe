{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4ddc25-6532-4ce5-918c-b97fdf812d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run data_pipelines.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432fa7c9-b0a8-48dd-a6b5-6b28e94e4bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from collections import defaultdict\n",
    "from datasets import Dataset, DatasetDict\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fb605d-60cd-40b7-a9e5-cff9d2d761f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    def __init__(self, chat_name, messages):\n",
    "        self.chat_name = chat_name\n",
    "        self.messages = messages\n",
    "\n",
    "    def to_text(self):\n",
    "        result = \"<<SYS>>Write a realistic text message chat. Avoid repetition.<</SYS>>\\n\"\n",
    "        \n",
    "        participants = {msg.sender_name for msg in self.messages}\n",
    "        for msg in self.messages:\n",
    "            participants.update(receiver for receiver in msg.receivers)\n",
    "\n",
    "        if len(participants) > 2:\n",
    "            result += f\"[INST]Write a chat in the group '{self.chat_name}' between {', '.join(participants)}[/INST]\\n\"\n",
    "        else:\n",
    "            participants.remove(\"Tiến Dũng Nguyễn\")\n",
    "            single_participant = participants.pop()\n",
    "            result += f\"[INST]Write a chat between Tiến Dũng Nguyễn and {single_participant}[/INST]\\n\"\n",
    "        \n",
    "        result += \" \".join(f\"### {message.sender_name}: {message.content}\" for message in self.messages)\n",
    "        return result\n",
    "\n",
    "    def token_len(self):\n",
    "        return len(tokenizer.encode(self.to_text()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8e0d9c-6eee-450d-9e9f-dc33e600b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token= os.getenv('HF_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adad03a2-d157-433e-a594-460731c5fb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83de35d4-0b2e-4819-ae4c-de6e139a0d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 200  \n",
    "\n",
    "def clump_messages():\n",
    "    documents = []\n",
    "    for chat_name, message_list in tqdm.tqdm(all_messages.items()):\n",
    "        pointer = 0\n",
    "        while pointer < len(message_list):\n",
    "            size = 1\n",
    "            current_document = Document(chat_name, [message_list[pointer]])\n",
    "            \n",
    "            while pointer + size < len(message_list):\n",
    "                next_message = message_list[pointer + size]\n",
    "                temp_document = Document(chat_name, current_document.messages + [next_message])\n",
    "                \n",
    "                if temp_document.token_len() >= MAX_LENGTH:\n",
    "                    break\n",
    "                \n",
    "                current_document = temp_document\n",
    "                size += 1\n",
    "            \n",
    "            documents.append(current_document)\n",
    "            pointer += size\n",
    "\n",
    "    return documents\n",
    "\n",
    "documents = clump_messages()\n",
    "print(f\"{len(documents):,} messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb47423c-8c6a-45bf-8d91-7e7ef76146e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [doc.to_text() for doc in documents]\n",
    "lengths = [doc.token_len() for doc in documents]\n",
    "counts = sum(d.count('###') for d in data)\n",
    "\n",
    "print(f'There are {counts:,} messages; average {counts/len(documents):.2} messages in each of {len(documents):,} documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab3aa7b-2533-425a-941c-268c714cc986",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.set_xlabel('Number of tokens in a document')\n",
    "ax.set_ylabel('Count of documents')\n",
    "ax.get_yaxis().set_major_formatter(matplotlib.ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
    "l2 = [min(MAX_LENGTH+100,l) for l in lengths]\n",
    "_ = ax.hist(l2, bins=range(0,MAX_LENGTH+50,10), color='darkorange', rwidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1574017-5d70-4021-9e7f-452f06b59523",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10f3eb9-53c1-45dc-8e7e-eca6ce408128",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.95 * len(data))\n",
    "train, test = data[:split], data[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd334c5-30e8-4ede-869d-e86da90c63b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict({'text': train})\n",
    "test_dataset = Dataset.from_dict({'text': test})\n",
    "dataset = DatasetDict({'train': train_dataset, 'test': test_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f57a85-1339-47fe-8934-51ad60e7abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.push_to_hub(\"simme\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709e8d47-3e12-452c-ae14-eb5599b684aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
